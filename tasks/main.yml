---
# Common to both with some quick sync code here.
- name: Set some initial facts
  ansible.builtin.set_fact:
    sync_type: "{{ sync_type | default('quick', true) }}"
    client: "{{ short_name | default(client, true) }}"
    canonical_server_client: "{{ canonical_site_short_name | default(canonical_server_client, true) }}"
    use_obfuscated: "{{ true if sync_obfuscated_dbs is defined and sync_obfuscated_dbs is true else false }}"

- name: test
  set_fact:
    my_var: "{{ client + ('_obfuscated' if use_obfuscated is true else '') }}"


- name: More initial facts - for borg restores only
  set_fact:
    repo_name: "{{ canonical_server_client + '-' + canonical_hostname }}"
    passphrase: "{{ lookup('community.general.passwordstore', canonical_server_client + '/' + canonical_hostname + '/borg/remote') }}"
  when: db_sync_strategy == 'rsyncnet' and not monitor_backupninja|bool
  no_log: true

# common to both
- name: repo name and passhphrase is different when we do site-level backups
  set_fact:
    repo_name: "{{ client + '-' + canonical_hostname + '-' + canonical_bare_url }}"
    passphrase: "{{ lookup('community.general.passwordstore', client + '/' + canonical_hostname + '/' + canonical_bare_url + '/borg/remote') }}"
  when: db_sync_strategy == 'rsyncnet' and monitor_backupninja|bool
  no_log: true

# unique to non-initial
- name: Ensure file owner/perms are correct
  file:
    path: "{{ webroot }}"
    state: directory
    mode: ug+rw
    owner: "{{ run_as_user }}"
    group: "{{ run_as_user }}"
    recurse: yes
  when: run_as_user != ansible_user

# unique to non-initial
- name: Ensure file owner/perms are correct (git)
  file:
    path: "{{ gitroot }}/.git"
    state: directory
    mode: ug+rw
    owner: "{{ run_as_user }}"
    group: "{{ run_as_user }}"
    recurse: yes
  when: run_as_user != ansible_user

# unique to non-initial
- name: git pull
  git:
    repo: "{{ git_repo_url }}"
    dest: "{{ gitroot }}"
    version: "{{ git_main_branch }}"
    track_submodules: no
    key_file: "{{ ssh_key_location + '/id_ed25519' if ssh_key_location is defined }}"
    ssh_opts: "{{ '-o UserKnownHostsFile=' + ssh_key_location + '/known_hosts' if ssh_key_location is defined }}"    
  become_user: "{{ run_as_user }}"
  when: git_repo_url is not none and (pantheon_site_code is not defined or pantheon_site_code == None)

# unique to non-initial
# Currently the Ansible source code hard-codes the assumption that your branch is called "master".  When that's fixed, we can remove this and just set `track_submodules` to "yes" above.
- name: git submodule update
  shell: git submodule update --remote
  args:
    chdir: "{{ gitroot }}"
  changed_when: false
  become_user: "{{ run_as_user }}"
  when: git_repo_url is not none and (pantheon_site_code is not defined or pantheon_site_code == None)

# unique to non-initial
- name: Use the empty logging db
  ansible.builtin.set_fact:
    canonical_crm_quicklogging_db_name: "{{ canonical_crm_logging_db_name }}_structure"
  when: sync_type == 'quick' and civicrm == 'Yes' and canonical_crm_logging_db_name is not none and db_sync_strategy != 'livedump'
  become_user: root

# common to both, but has some unique code for quick db syncs.
- name: create a list of db names
  set_fact:
    canonical_db_names:
      - "{{ canonical_cms_db_name + ('_obfuscated' if use_obfuscated is true else '') }}"
      - "{{ canonical_crm_db_name + ('_obfuscated' if use_obfuscated is true else '') }}"
      - "{{ canonical_crm_quicklogging_db_name if use_obfuscated is true else canonical_crm_quicklogging_db_name | default(canonical_crm_logging_db_name, true) | default(canonical_crm_db_name, true) }}"
    db_names:
      - "{{ cms_db_name }}"
      - "{{ crm_db_name }}"
      - "{{ crm_logging_db_name | default(crm_db_name, true) }}"

# common to both
- name: create a list of unique db names, removing blanks
  set_fact:
    canonical_db_names_unique: "{{ canonical_db_names | select() | unique }}"
    db_names_unique: "{{ db_names | select() | unique }}"

# unique to non-initial but why?
# Normally, sql-dumps is parallel with the webroot.  In certain situations (when gitroot is above webroot) this folder may not exists and creating it screws up git cloning.  
# In that situation, we'll use a temp directory and create sql-dumps next time, once we have a .gitignore in place.
- name: Check if .gitignore exists
  stat:
    path: "{{ gitroot }}/.gitignore"
  register: gitignore

# unique to non-initial but why?
- name: Create sql-dumps folder
  file:
    owner: "{{ run_as_user }}"
    group: "{{ run_as_user }}"
    path: "{{ sqldumps_path }}"
    state: directory
    mode: 02770
  become_user: "{{ run_as_user }}"
  when: gitignore.stat.exists

- name: Check if sql-dumps dir exists
  stat:
    path: "{{ sqldumps_path }}"
  register: dumps_dir

- name: Set the sql-dumps directory var
  set_fact:
    # This is the directory on the server where the db will actually be imported.
    sql_dumps_dir: "{{ sqldumps_path if dumps_dir.stat.exists else '/tmp' }}"
    # This is where a live dump is downloaded, which is different if we're pulling to a non-local server.
    sql_dumps_download_dir: "{{ sqldumps_path if (dumps_dir.stat.exists and group_names is search('localhost')) or db_sync_strategy != 'livedump' else '/tmp' }}"

# MySQL restore
- name: Check if db dump files already exist
  stat:
    path: "{{ sql_dumps_dir }}/{{ canonical_cms_db_name }}.sql"
    get_mime: false
    get_attributes: false
    get_checksum: false
  register: db_dump

# Return yes when we FAIL the assertion, meaning "restore a db backup".
- name: Update the dump if a canonical db exists unless a dump already exists and is < 24hrs old
  assert:
    that:
      - "(canonical_hostname is none and db_sync_strategy != 'pantheon') or (db_dump.stat.exists == true and (ansible_date_time.epoch|int - db_dump.stat.mtime) < (60 * 60 * 24))"
    fail_msg: "yes"
  failed_when: false
  register: acquire_db_backup

# Acquire a backup from rsync.net
- block:
  - name: Get the latest backup archive name
    shell: borg list {{ '--glob-archives=*' + backup_date if backup_date is defined }} --last 1 --short --remote-path borg12 {{ rsyncnet_user }}@{{ rsyncnet_server }}:{{ repo_name }}
    environment:
      BORG_PASSPHRASE: "{{ passphrase }}"
      BORG_RSH: "{{ 'ssh -o UserKnownHostsFile=' + ssh_key_location + '/known_hosts -i ' + ssh_key_location + '/id_ed25519' if ssh_key_location is defined else 'ssh' }}"
      BORG_RELOCATED_REPO_ACCESS_IS_OK: "yes"
    register: archive_name
    changed_when: false

  # Download the borg backup of the db dump if we need an update and the borg backup exists.
  # Also very ugly.  Borg doesn't allow specifying a destination path, so we use strip-components, but need to figure out how many components the path has.
  - name: Get depth of backup path.
    set_fact:
      path_depth: "{{ canonical_database_backup_path | default('var/backups/mysql/sqldump',true) | regex_replace('[^\/]', '') | count + 1 }}"

  - name: Download the latest copy of the database
    shell: borg extract --strip-components {{ path_depth }} --remote-path borg12 {{ rsyncnet_user }}@{{ rsyncnet_server }}:{{ repo_name }}::{{ archive_name.stdout }} {{ canonical_database_backup_path | default("var/backups/mysql/sqldump",true) }}/{{ db_name }}.sql.gz
    args:
      chdir: "{{ sql_dumps_dir }}"
    environment:
      BORG_PASSPHRASE: "{{ passphrase }}"
      BORG_RSH: "{{ 'ssh -o UserKnownHostsFile=' + ssh_key_location + '/known_hosts -i ' + ssh_key_location + '/id_ed25519' if ssh_key_location is defined else 'ssh' }}"
    with_items: "{{ canonical_db_names_unique }}"
    register: db_downloaded
    loop_control:
      loop_var: db_name
    become_user: root

  - name: Decompress the db backups
    shell: gunzip --force {{ item }}.sql.gz
    args:
      chdir: "{{ sql_dumps_dir }}"
    with_items: "{{ canonical_db_names_unique }}"
    when: acquire_db_backup.msg == "yes"
    become_user: root
  when: acquire_db_backup.msg == "yes" and db_sync_strategy == 'rsyncnet'

# Acquire a backup from a mysqldump
- block:
  - name: Make a db backup
    mysql_db:
      state: dump
      login_user: "{{ canonical_db_user }}"
      login_password: "{{ lookup('community.general.passwordstore', canonical_server_client + '/' + canonical_hostname + '/' + canonical_bare_url + '/mysql') }}"
      login_host: "{{ remote_db_host }}"
      name: "{{ db_name }}"
      target: "/tmp/{{ db_name }}.sql"
      single_transaction: true
      dump_extra_args: "{% if db_name == canonical_crm_logging_db_name and sync_type == 'quick' %}--no-data{% else %}--routines{% endif %}"
    with_items: "{{ canonical_db_names_unique }}"
    loop_control:
      loop_var: db_name

  #FIXME: Change to ansible.posix.synchronize. But is screwed up because "synchronize" treats "delegate_to" differently.
  - name: fetch db backups
    fetch:
      src: "/tmp/{{ db_name }}.sql"
      dest: "{{ sql_dumps_download_dir }}/{{ db_name }}.sql"
      flat: yes
    with_items: "{{ canonical_db_names_unique }}"
    become_user: "{{ run_as_user }}"
    loop_control:
      loop_var: db_name

  when: acquire_db_backup.msg == "yes" and db_sync_strategy == 'livedump'
  delegate_to: "{{ canonical_server }}"
  remote_user: "{{ canonical_run_as_user }}"
  become: no

- name: Send live dumps to destination server
  ansible.posix.synchronize:
    src: "{{ sql_dumps_download_dir }}/{{ db_name }}.sql"
    dest: "{{ sql_dumps_dir }}/{{ db_name }}.sql"
    mode: push

  when: acquire_db_backup.msg == "yes" and db_sync_strategy == 'livedump'
  become: no
  with_items: "{{ canonical_db_names_unique }}"
  loop_control:
    loop_var: db_name

# Acquire a backup from Pantheon
- block:
  - name: Log in to Terminus
    command: "terminus auth:login --machine-token={{ lookup('community.general.passwordstore', client + '/pantheonmachinetoken') }}"

  - name: Create a Pantheon backup
    command: "terminus backup:create {{ pantheon_site_code }}.live --element=db --keep-for=1"

  - name: Retrieve the Pantheon backup
    command: "terminus backup:get {{ pantheon_site_code }}.live --element=db --to={{ sql_dumps_dir }}/{{ canonical_cms_db_name }}.sql.gz"

  - name: Decompress the db backup
    shell: gunzip --force {{ canonical_cms_db_name }}.sql.gz
    args:
      chdir: "{{ sql_dumps_dir }}"
  when: acquire_db_backup.msg == "yes" and db_sync_strategy == 'pantheon'
  become_user: "{{ run_as_user }}"

- name: Set owner/group for db dumps
  ansible.builtin.file:
    path: "{{ sql_dumps_download_dir }}/{{ db_name }}.sql"
    owner: "{{ run_as_user }}"
    group: "{{ run_as_user }}"
    mode: 0660
  with_items: "{{ canonical_db_names_unique }}"
  become_user: root
  loop_control:
    loop_var: db_name
  # Not on livedumps we don't.
  when: db_sync_strategy == 'rsyncnet'

# Speed optimizations
- block:
  # Use `sed` here because Perl runs out of RAM on multiline comparisons on files over a certain size.
  # `-E` allows extended regex like \w.  Separating two regexes with a comma handles all lines from A to B. `d` deletes them.
  - name: Strip out data on big useless tables.
    command: sed -i -E '/-- Dumping data for table `(log_civicrm\w+|civicrm_mailing_event\w+|civicrm_(job_)?log|civicrm_mailing_recipients)`/,/UNLOCK TABLES/d' {{ canonical_crm_db_name + ('_obfuscated' if use_obfuscated is true else '') }}.sql
    args:
      chdir: "{{ sql_dumps_dir }}"
  when: sync_type == 'quick' and civicrm == 'Yes'
  become_user: root

- name: Remove trigger/view/function definers from Civi db
  command: perl -pi -e 's#\/\*\!5001. DEFINER=`.*`@`.*?\*\/##g; s/CREATE DEFINER.*FUNCTION/CREATE FUNCTION/g' {{ canonical_crm_db_name + ('_obfuscated' if use_obfuscated is true else '') }}.sql
  args:
    chdir: "{{ sql_dumps_dir }}"
  become_user: root
  when: civicrm == 'Yes'

# Another hack.  Temporary enough that I'm not doing anything further.
- name: Convert MySQL 8-only collation
  command: perl -pi -e 's/collation_connection += utf8mb4_0900_ai_ci/collation_connection = utf8mb4_general_ci/g' {{ canonical_crm_db_name + ('_obfuscated' if use_obfuscated is true else '') }}.sql
  args:
    chdir: "{{ sql_dumps_dir }}"
  become_user: root
  when: civicrm == 'Yes' and (run_as_user == 'opsig' or run_as_user is search("nasco"))

- name: Fix logging db triggers when using a separate db
  command: perl -pi -e 's/{{ canonical_crm_logging_db_name }}/{{ crm_logging_db_name }}/g' {{ canonical_crm_db_name + ('_obfuscated' if use_obfuscated is true else '') }}.sql
  args:
    chdir: "{{ sql_dumps_dir }}"
  when: canonical_crm_logging_db_name is not none and civicrm == 'Yes'
  become_user: root

- name: Fix multilingual view definers in the logging db (if separate)
  command: perl -pi -e 's#\/\*\!5001. DEFINER=`.*`@`.*?\*\/##g' {{ item }}.sql
  args:
    chdir: "{{ sql_dumps_dir }}"
  when: canonical_crm_logging_db_name is not none and civicrm == 'Yes' and canonical_crm_logging_db_name != canonical_crm_db_name
  become_user: root
  with_items:
   - "{{ canonical_crm_quicklogging_db_name|default('none', True) }}"
   - "{{ canonical_crm_logging_db_name }}"

- name: Ensure the CMS is installed
  stat:
    path: "{{ webroot }}/index.php"
  register: cms_exists

- name: Drop the databases
  community.mysql.mysql_db:
    name:
      - "{{ item }}"
    state: absent
  with_items: "{{ db_names_unique }}"

- name: Import the databases
  community.mysql.mysql_db:
    name: "{{ item.1 }}"
    target: "{{ sql_dumps_dir }}/{{ item.0 }}.sql"
    state: import
    login_host: "{{ db_host|default('localhost') }}"
    login_user: "{{ db_user }}"
    login_password: "{{ lookup('community.general.passwordstore', client + '/' + hostname + '/' + bare_url + '/mysql') }}"
  when: item.1 is defined and cms_exists.stat is defined and cms_exists.stat.exists == true and canonical_primary_url
  become_user: root
  with_together:
   - "{{ canonical_db_names_unique }}"
   - "{{ db_names_unique }}"

- name: Composer install (D8)
  composer:
    command: install
    working_dir: "{{ gitroot }}"
    composer_executable: "{{ ansible_env.HOME + '/bin/composer' if 'mayfirst_ng_site' in group_names else omit }}"
    executable: "{{ php_path|default(omit) }}"
  when: cms == "Drupal8"
  become_user: "{{ run_as_user }}"

- name: Turn off Nagios cron check on dev/test sites
  command: "drush --root={{ webroot }} -y vset nagios_func_cron 0"
  when: cms == 'Drupal' and env != 'Live'

- name: Fix wp-load setting
  command: wp eval '$c=[civi_wp()->admin, "add_wpload_setting"]; if (is_callable($c)) $c();' --path={{ webroot }}
  become_user: "{{ run_as_user }}"
  when: cms == 'WordPress' and civicrm == 'Yes'
  ignore_errors: yes

- name: search/replace in wp_blogs for multi-site
  command: "wp search-replace {{ canonical_bare_url }} {{ bare_url }} wp_blogs --path={{ webroot }}"
  become_user: "{{ run_as_user }}"
  when: cms == 'WordPress'
  ignore_errors: yes

- name: Do a search/replace for the primary URL
  command: "wp search-replace {{ canonical_primary_url }} {{ primary_url }} --path={{ webroot }}"
  become_user: "{{ run_as_user }}"
  when: cms == 'WordPress'
  ignore_errors: yes

- name: Disable Drupal modules that screw with login (on dev)
  command: "drush --root={{ webroot }} -y pm-disable captcha"
  become_user: "{{ run_as_user }}"
  failed_when: false
  when: cms == 'Drupal' and env == 'Dev'

- name: Disable wp plugins that screw with login (on dev)
  command: wp plugin deactivate advanced-nocaptcha-recaptcha ithemes-security-pro wps-hide-login --path={{ webroot }}
  become_user: "{{ run_as_user }}"
  failed_when: false
  when: cms == 'WordPress' and env == 'Dev'

- name: cv flush
  shell: "PATH=$HOME/bin:$PATH;cv flush --cwd {{ webroot }}"
  when: civicrm == 'Yes'
  become_user: "{{ run_as_user }}"

- name: drush cc all
  shell: "PATH=$HOME/bin:$PATH;drush cc all -y --root={{ webroot }}"
  when: cms == 'Drupal'
  become_user: "{{ run_as_user }}"

- name: drush cr
  shell: "PATH=$HOME/bin:$PATH;{{ gitroot }}/vendor/bin/drush cr --root={{ webroot }}"
  when: cms == 'Drupal8'
  become_user: "{{ run_as_user }}"

- name: wp cache flush
  shell: "PATH=$HOME/bin:$PATH;wp cache flush --path={{ webroot }}"
  when: cms == 'WordPress'
  become_user: "{{ run_as_user }}"
